---
title: "Lab 4c. Deep Learning - iNaturalist"
editor_options: 
  chunk_output_type: inline
---
# Set Up 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
```

# Data Pre-Processing 

```{r}
librarian::shelf(
  digest, dplyr)

# path to folder containing species directories of images
dir_train_mini <- "/courses/EDS232/inaturalist-2021/train_mini"

# path to output table of paths, which could be read by R, eg read_csv(), or Python, eg 
inat_spp_dirs_csv <- "~/inat_species_dirs.csv"

# get list of directories, one per species (n = 10,000 species)
dirs_spp <- list.dirs(dir_train_mini, recursive = F)
n_spp <- length(dirs_spp)
n_spp
```


```{r}
# set seed (for reproducible results) 
# just before sampling (otherwise get different results)
# based on your username (unique amongst class)
Sys.info()[["user"]] %>% 
  digest::digest2int() %>% 
  set.seed()
i10 <- sample(1:n_spp, 10)

# show the 10 indices sampled of the 10,000 possible 
i10
```


```{r}
# show the 10 species directory names 
basename(dirs_spp)[i10]
```


```{r}
# show the first 2 species directory names
i2 <- i10[1:2]
basename(dirs_spp)[i2]

obtusa <- basename(dirs_spp)[i2][1]
chinensis <- basename(dirs_spp)[i2][2]

```

```{r}
# path to output table of paths, which could be read by R, eg readr::read_csv(), or Python, eg pandas.read_csv()
inat_spp_images_csv <- "~/inat_spp_images.csv"

d <- tibble(
  # get 10 species names
  species = basename(dirs_spp)[i10],
  # assign TRUE/FALSE for: 10 species (multi-class) and 2 species (binary)
  spp10 = TRUE,
  spp2  = c(T,T,rep(F,8)))
DT::datatable(d)
```

```{r}
d <- d %>% 
  mutate(
    # construct full path to species directory
    dir_species = file.path(dir_train_mini, species),
    tbl_images  = purrr::map(dir_species, function(dir){
      # create a tibble per species
      tibble(
        # list files in the species directory (n=50)
        image = list.files(dir),
        # assign subset per species
        subset = c(rep("train", 30), rep("validation", 10), rep("test", 10))) })) %>% 
  # go from a tibble with 10 species rows containing a nested tbl_images to unnested, ie 10 species * 50 images = 500 rows
  tidyr::unnest(tbl_images)

# write tibble to CSV file for subsequent reading
readr::write_csv(d, inat_spp_images_csv)

# show counts of image files per species and subset
d %>% 
  mutate(
    # truncate species to show one line per species
    species_trunc = stringr::str_trunc(species, 40)) %>% 
  select(species_trunc, subset) %>% 
  table()
```

Your task is to apply your deep learning skills to build the following models:

# 1. **2 Species (binary classification) - neural net**. 

Draw from [3.4 üçø Movies (binary classification)](./lab4b_examples.html). You'll need to pre-process the images to be a consistent shape first though -- see 5.2.4 Data preprocessing.

```{r}
library(keras)
```

## Subset the data 
- train: n = 30 
- validate: n = 10 
- test: n = 10 
```{r}
train_sub <- subset(d, d$subset == "train")
train_data <- train_sub[sample(nrow(train_sub), size = 30, replace = FALSE), ]

validate_sub <- subset(d, d$subset == "validation")
validate_data <- validate_sub[sample(nrow(validate_sub), size = 10, replace = FALSE), ]

test_sub <- subset(d, d$subset == "test")
test_data <- test_sub[sample(nrow(test_sub), size = 10, replace = FALSE), ]
```











# Create training, validation, and test datasets 
```{r}
original_dataset_dir <- "/courses/EDS232/inaturalist-2021/train_mini"
base_dir             <- "~/eds232/eds232-dl/data"

train_dir           <- file.path(base_dir, "train")
train_obtusa_dir      <- file.path(train_dir, "obtusa")
train_chinensis_dir      <- file.path(train_dir, "chinensis")
validation_dir      <- file.path(base_dir, "validation")
validation_obtusa_dir <- file.path(validation_dir, "obtusa")
validation_chinensis_dir <- file.path(validation_dir, "chinensis")
test_dir            <- file.path(base_dir, "test")
test_obtusa_dir       <- file.path(test_dir, "obtusa")
test_chinensis_dir       <- file.path(test_dir, "chinensis")
```

```{r}
dir.create(base_dir)
dir.create(train_dir)
dir.create(validation_dir)
dir.create(test_dir)
dir.create(train_obtusa_dir)
dir.create(train_chinensis_dir)
dir.create(validation_obtusa_dir)
dir.create(validation_chinensis_dir)
dir.create(test_obtusa_dir)
dir.create(test_chinensis_dir)
```

```{r}
ch_dir <- paste0("/courses/EDS232/inaturalist-2021/train_mini/", ch)
files = list.files(ch_dir, full.names = TRUE)
head(basename(files))

for(i in 1:length(files)){
  print(basename(files[i]))
}

file.copy(file.path(ch_dir, basename(files)[1:10]), train_chinensis_dir, overwrite = TRUE)
```


```{r}
 

```


```{r}
fnames <- 
file.copy(file.path(ch_dir, fnames), 
          file.path(train_obtusa_dir)) 
```


```{r}
# All images will be rescaled by 1/255
train_datagen <- image_data_generator(rescale = 1/255)
validation_datagen <- image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_directory(
  # This is the target directory
  train_dir,
  # This is the data generator
  train_datagen,
  # All images will be resized to 150x150
  target_size = c(150, 150),
  batch_size = 20,
  # Since we use binary_crossentropy loss, we need binary labels
  class_mode = "binary")

validation_generator <- flow_images_from_directory(
  validation_dir,
  validation_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "binary")
```


# **2 Species (binary classification) - convolutional neural net**. Draw from the [dogs vs cats example](https://bbest.github.io/eds232-ml/lab4c_5.2.small-convnets.html).

# **10 Species (multi-class classification) - neural net**.  Draw from [3.5 üì∞ Newswires (multi-class classification)](./lab4b_examples.html).

```{r}
library(keras)

reuters <- dataset_reuters(num_words = 10000)
c(c(train_data, train_labels), c(test_data, test_labels)) %<-% reuters
```


# **10 Species (multi-class classification) - convolutional neural net**. Draw from [dogs vs cats example](https://bbest.github.io/eds232-ml/lab4c_5.2.small-convnets.html) and update necessary values to go from binary to mult-class classification.

In your models, be sure to include the following:

- Split the original images per species (n=50) into train (n=30), validate (n=10) and test (n=10). These are almost absurdly few files to feed into these complex deep learning models but will serve as a good learning example.

- Include accuracy metric and validation in the fitting process and history plot.

- Evaluate loss and accuracy on your test model results. Compare standard neural network and convolutional neural network results.
